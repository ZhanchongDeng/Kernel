{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA4 - String Kernals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zhanchong Deng  \n",
    "A15491777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kernel as pa4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pa4.loadData('data/pa4train.txt')\n",
    "testing = pa4.loadData('data/pa4test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse them into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.array(pd.DataFrame(training).astype({0:str, 1:int}))\n",
    "testing = np.array(pd.DataFrame(testing).astype({0:str, 1:int}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer: only train if there is something wrong with original algorithm. Training takes very long  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each p in **saved/delta_idx_.csv** to avoid long training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half way done\n",
      "All done\n",
      "Half way done\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "for length in [3,4,5]:\n",
    "    p = pa4.Perceptron()\n",
    "    p.fit(training, length)\n",
    "    pd.DataFrame(p.delta, columns=['x','y']).to_csv(\"saved/delta\"+ str(length) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Training/Testing Error for each p with k(s,t) = #occurances in s * #occurances in t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error for (p=3 )is: 0.011846\n",
      "Testing Error for (p=3 )is: 0.052770\n",
      "Training Error for (p=4 )is: 0.007163\n",
      "Testing Error for (p=3 )is: 0.027704\n",
      "Training Error for (p=5 )is: 0.003581\n",
      "Testing Error for (p=5 )is: 0.030343\n"
     ]
    }
   ],
   "source": [
    "for length in [3,4,5]:\n",
    "    p.delta = np.array(pd.read_csv(filepath_or_buffer=\"saved/delta\"+ str(length) + \".csv\", usecols=['x','y']))\n",
    "    p.p = length\n",
    "    print(\"Training Error for (p =\", length, \")is:\", p.error(training))\n",
    "    print(\"Testing Error for (p=\", length, \")is:\", p.error(testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train with second kernel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half way done\n",
      "Half way done\n",
      "Half way done\n"
     ]
    }
   ],
   "source": [
    "for length in [3,4,5]:\n",
    "    p2 = pa4.Perceptron()\n",
    "    p2.fit(training, length)\n",
    "    pd.DataFrame(p2.delta_idx, columns=['delta_idx']).to_csv(\"saved2/delta_idx\"+ str(length) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Training/Testing Error for each p with k(s,t) = #common words only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error for (p=3 )is: 0.012121\n",
      "Testing Error for (p=3 )is: 0.040897\n",
      "Training Error for (p=4 )is: 0.006612\n",
      "Testing Error for (p=3 )is: 0.025066\n",
      "Training Error for (p=5 )is: 0.003581\n",
      "Testing Error for (p=5 )is: 0.030343\n"
     ]
    }
   ],
   "source": [
    "for length in [3,4,5]:\n",
    "    p2.delta_idx = pd.read_csv(\"saved2/delta_idx\"+ str(length) + \".csv\")['delta_idx'].to_list()\n",
    "    p2.p = length\n",
    "    print(\"Training Error for (p =\", length, \")is:\", p2.error(training))\n",
    "    print(\"Testing Error for (p=\", length, \")is:\", p2.error(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
